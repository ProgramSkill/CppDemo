# NLP Glossary (自然语言处理词汇表)

## English-Chinese Technical Terms

---

## 1. 基础概念 (Fundamental Concepts)

| English | 中文 | 说明 |
|---------|------|------|
| **Natural Language Processing** | 自然语言处理 | 计算机理解人类语言 |
| **NLP** | NLP | 自然语言处理缩写 |
| **Corpus** | 语料库 | 文本数据集合 |
| **Token** | 词元 | 文本的基本单位 |
| **Vocabulary** | 词汇表 | 所有词的集合 |
| **Document** | 文档 | 一段文本 |

---

## 2. 文本预处理 (Text Preprocessing)

| English | 中文 | 说明 |
|---------|------|------|
| **Tokenization** | 分词 | 切分文本为词元 |
| **Stemming** | 词干提取 | 去除词缀 |
| **Lemmatization** | 词形还原 | 还原词原形 |
| **Stop Words** | 停用词 | 无意义的常见词 |
| **Part-of-Speech (POS)** | 词性标注 | 名词、动词等 |
| **Normalization** | 标准化 | 统一文本格式 |

---

## 3. 文本表示 (Text Representation)

| English | 中文 | 说明 |
|---------|------|------|
| **Bag of Words** | 词袋模型 | 词频表示 |
| **TF-IDF** | TF-IDF | 词频-逆文档频率 |
| **N-gram** | N元语法 | 连续N个词 |
| **Word Embedding** | 词嵌入 | 词的向量表示 |
| **Word2Vec** | Word2Vec | 词嵌入算法 |
| **GloVe** | GloVe | 全局向量表示 |
| **FastText** | FastText | 子词嵌入 |

---

## 4. NLP任务 (NLP Tasks)

| English | 中文 | 说明 |
|---------|------|------|
| **Text Classification** | 文本分类 | 分类文本 |
| **Sentiment Analysis** | 情感分析 | 分析情感倾向 |
| **Named Entity Recognition** | 命名实体识别 | 识别实体 |
| **NER** | NER | 命名实体识别缩写 |
| **Part-of-Speech Tagging** | 词性标注 | 标注词性 |
| **Machine Translation** | 机器翻译 | 语言翻译 |
| **Question Answering** | 问答系统 | 回答问题 |
| **Text Summarization** | 文本摘要 | 生成摘要 |
| **Text Generation** | 文本生成 | 生成文本 |
| **Language Modeling** | 语言建模 | 预测下一个词 |

---

## 5. 序列模型 (Sequence Models)

| English | 中文 | 说明 |
|---------|------|------|
| **Sequence-to-Sequence** | 序列到序列 | Seq2Seq模型 |
| **Encoder-Decoder** | 编码器-解码器 | 编解码架构 |
| **Attention Mechanism** | 注意力机制 | 关注重要部分 |
| **Bidirectional** | 双向 | 双向处理 |
| **Context Vector** | 上下文向量 | 编码后的表示 |

---

## 6. Transformer相关 (Transformer Related)

| English | 中文 | 说明 |
|---------|------|------|
| **BERT** | BERT | 双向编码器 |
| **GPT** | GPT | 生成式预训练 |
| **Transformer** | Transformer | 注意力架构 |
| **Pre-training** | 预训练 | 大规模预训练 |
| **Fine-tuning** | 微调 | 任务特定训练 |
| **Masked Language Model** | 掩码语言模型 | BERT的训练方式 |
| **Causal Language Model** | 因果语言模型 | GPT的训练方式 |
| **Tokenizer** | 分词器 | 文本转ID |

---

## 7. 大语言模型 (Large Language Models)

| English | 中文 | 说明 |
|---------|------|------|
| **Large Language Model** | 大语言模型 | LLM |
| **Prompt** | 提示 | 输入给模型的文本 |
| **Prompt Engineering** | 提示工程 | 设计提示 |
| **In-Context Learning** | 上下文学习 | 从示例学习 |
| **Zero-Shot** | 零样本 | 无示例推理 |
| **Few-Shot** | 少样本 | 少量示例推理 |
| **Chain of Thought** | 思维链 | 逐步推理 |
| **Instruction Tuning** | 指令微调 | 指令跟随训练 |
| **RLHF** | RLHF | 人类反馈强化学习 |

---

## 常用缩写 (Common Abbreviations)

| 缩写 | 英文全称 | 中文 |
|------|----------|------|
| **NLP** | Natural Language Processing | 自然语言处理 |
| **NLU** | Natural Language Understanding | 自然语言理解 |
| **NLG** | Natural Language Generation | 自然语言生成 |
| **NER** | Named Entity Recognition | 命名实体识别 |
| **POS** | Part-of-Speech | 词性 |
| **BERT** | Bidirectional Encoder Representations from Transformers | 双向编码器 |
| **GPT** | Generative Pre-trained Transformer | 生成式预训练 |
| **LLM** | Large Language Model | 大语言模型 |
| **RLHF** | Reinforcement Learning from Human Feedback | 人类反馈强化学习 |

---

**最后更新**: 2024-01-29
