# Information Theory (信息论)

信息论为理解机器学习中的损失函数和模型压缩提供理论基础。

## 📚 内容概览

| 主题 | 描述 | 难度 |
|------|------|------|
| 熵 | 不确定性度量 | ⭐⭐ |
| 交叉熵 | 分类损失函数 | ⭐⭐ |
| KL散度 | 分布差异度量 | ⭐⭐⭐ |
| 互信息 | 变量相关性 | ⭐⭐⭐ |

## 🎯 学习目标

- 理解熵的概念和计算
- 掌握交叉熵损失函数
- 理解KL散度在ML中的应用

## 💡 核心公式

```
熵: H(X) = -Σ P(x)log P(x)
交叉熵: H(P,Q) = -Σ P(x)log Q(x)
KL散度: D_KL(P||Q) = Σ P(x)log(P(x)/Q(x))
```
