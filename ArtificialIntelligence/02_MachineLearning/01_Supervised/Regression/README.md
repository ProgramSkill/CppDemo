# å›å½’ç®—æ³•è¯¦è§£ï¼ˆRegressionï¼‰

## ğŸ“š ç›®å½•

- [ä»€ä¹ˆæ˜¯å›å½’](#ä»€ä¹ˆæ˜¯å›å½’)
- [ç®—æ³•åˆ—è¡¨](#ç®—æ³•åˆ—è¡¨)
- [å…¥é—¨æ•™ç¨‹](#å…¥é—¨æ•™ç¨‹)
- [è¿›é˜¶æ•™ç¨‹](#è¿›é˜¶æ•™ç¨‹)
- [ç²¾é€šæ•™ç¨‹](#ç²¾é€šæ•™ç¨‹)
- [å®æˆ˜æ¡ˆä¾‹](#å®æˆ˜æ¡ˆä¾‹)

## ä»€ä¹ˆæ˜¯å›å½’

å›å½’åˆ†ææ˜¯é¢„æµ‹**è¿ç»­æ•°å€¼**çš„ç›‘ç£å­¦ä¹ ä»»åŠ¡ã€‚ç»™å®šè¾“å…¥ç‰¹å¾ï¼Œé¢„æµ‹ä¸€ä¸ªå®æ•°è¾“å‡ºã€‚

### å…¸å‹åº”ç”¨åœºæ™¯
- ğŸ“ˆ æˆ¿ä»·é¢„æµ‹ï¼šæ ¹æ®é¢ç§¯ã€ä½ç½®ç­‰é¢„æµ‹ä»·æ ¼
- ğŸŒ¡ï¸ æ¸©åº¦é¢„æµ‹ï¼šæ ¹æ®å†å²æ•°æ®é¢„æµ‹æœªæ¥æ¸©åº¦
- ğŸ’° é”€å”®é¢„æµ‹ï¼šæ ¹æ®å¹¿å‘ŠæŠ•å…¥é¢„æµ‹é”€å”®é¢
- ğŸ“Š è‚¡ç¥¨ä»·æ ¼é¢„æµ‹ï¼šæ ¹æ®å†å²æ•°æ®é¢„æµ‹æœªæ¥ä»·æ ¼

### å›å½’ vs åˆ†ç±»
| å›å½’ | åˆ†ç±» |
|------|------|
| è¾“å‡ºè¿ç»­å€¼ï¼ˆå¦‚23.5ï¼‰ | è¾“å‡ºç¦»æ•£ç±»åˆ«ï¼ˆå¦‚"çŒ«"æˆ–"ç‹—"ï¼‰ |
| é¢„æµ‹"å¤šå°‘" | é¢„æµ‹"æ˜¯ä»€ä¹ˆ" |

## ç®—æ³•åˆ—è¡¨

æœ¬æ¨¡å—åŒ…å«4ä¸ªæ ¸å¿ƒå›å½’ç®—æ³•ï¼š

| ç®—æ³• | éš¾åº¦ | é€‚ç”¨åœºæ™¯ | å…³é”®ç‰¹ç‚¹ |
|------|------|----------|----------|
| **LinearRegression** | â­ | çº¿æ€§å…³ç³»æ•°æ® | æœ€ç®€å•ï¼Œæ˜“è§£é‡Š |
| **RidgeRegression** | â­â­ | ç‰¹å¾ç›¸å…³æ€§é«˜ | L2æ­£åˆ™åŒ–ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ |
| **LassoRegression** | â­â­â­ | éœ€è¦ç‰¹å¾é€‰æ‹© | L1æ­£åˆ™åŒ–ï¼Œäº§ç”Ÿç¨€ç–è§£ |
| **PolynomialRegression** | â­â­ | éçº¿æ€§å…³ç³» | æ‹Ÿåˆæ›²çº¿å…³ç³» |

---

## å…¥é—¨æ•™ç¨‹

### ç¬¬1è¯¾ï¼šçº¿æ€§å›å½’åŸºç¡€

#### ç†è®ºåŸºç¡€

çº¿æ€§å›å½’å‡è®¾è¾“å…¥å’Œè¾“å‡ºä¹‹é—´å­˜åœ¨çº¿æ€§å…³ç³»ï¼š

```
y = wâ‚€ + wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + wâ‚™xâ‚™
```

- `y`: é¢„æµ‹å€¼
- `wâ‚€`: æˆªè·ï¼ˆbiasï¼‰
- `wâ‚, wâ‚‚, ..., wâ‚™`: æƒé‡ï¼ˆweightsï¼‰
- `xâ‚, xâ‚‚, ..., xâ‚™`: ç‰¹å¾

**ç›®æ ‡**ï¼šæ‰¾åˆ°æœ€ä½³çš„æƒé‡ï¼Œä½¿é¢„æµ‹å€¼ä¸çœŸå®å€¼çš„è¯¯å·®æœ€å°ã€‚

#### ä»£ç ç¤ºä¾‹ï¼šç®€å•çº¿æ€§å›å½’

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Regression;
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

// ç¤ºä¾‹ï¼šæ ¹æ®å­¦ä¹ æ—¶é—´é¢„æµ‹è€ƒè¯•æˆç»©
double[,] X = new double[,] {
    { 1 },   // å­¦ä¹ 1å°æ—¶
    { 2 },   // å­¦ä¹ 2å°æ—¶
    { 3 },   // å­¦ä¹ 3å°æ—¶
    { 4 },   // å­¦ä¹ 4å°æ—¶
    { 5 }    // å­¦ä¹ 5å°æ—¶
};

double[] y = new double[] { 50, 60, 70, 80, 90 }; // å¯¹åº”æˆç»©

// 1. åˆ›å»ºæ¨¡å‹
var model = new LinearRegression();

// 2. è®­ç»ƒæ¨¡å‹
model.Fit(X, y);

// 3. é¢„æµ‹
double[,] XTest = new double[,] { { 3.5 } }; // å­¦ä¹ 3.5å°æ—¶
double[] predictions = model.Predict(XTest);

Console.WriteLine($"é¢„æµ‹æˆç»©: {predictions[0]}åˆ†");

// 4. è¯„ä¼°æ¨¡å‹
double[] yPred = model.Predict(X);
double mse = RegressionMetrics.MeanSquaredError(y, yPred);
double r2 = RegressionMetrics.RSquared(y, yPred);

Console.WriteLine($"MSE: {mse:F2}");
Console.WriteLine($"RÂ²: {r2:F2}");
```

#### ç»ƒä¹ é¢˜

1. **åŸºç¡€ç»ƒä¹ **ï¼šé¢„æµ‹æˆ¿ä»·
   - è¾“å…¥ï¼šæˆ¿å±‹é¢ç§¯ï¼ˆå¹³æ–¹ç±³ï¼‰
   - è¾“å‡ºï¼šä»·æ ¼ï¼ˆä¸‡å…ƒï¼‰
   - æ•°æ®ï¼š{50â†’150, 80â†’240, 120â†’360, 150â†’450}

2. **è¿›é˜¶ç»ƒä¹ **ï¼šå¤šç‰¹å¾å›å½’
   - è¾“å…¥ï¼šé¢ç§¯ã€æˆ¿é—´æ•°ã€æ¥¼å±‚
   - è¾“å‡ºï¼šä»·æ ¼
   - å°è¯•åˆ†ææ¯ä¸ªç‰¹å¾çš„é‡è¦æ€§

### ç¬¬2è¯¾ï¼šç†è§£æŸå¤±å‡½æ•°

#### å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰

æœ€å¸¸ç”¨çš„å›å½’æŸå¤±å‡½æ•°ï¼š

```
MSE = (1/n) Î£(yáµ¢ - Å·áµ¢)Â²
```

- `yáµ¢`: çœŸå®å€¼
- `Å·áµ¢`: é¢„æµ‹å€¼
- `n`: æ ·æœ¬æ•°é‡

**ç‰¹ç‚¹**ï¼š
- å¯¹å¤§è¯¯å·®æƒ©ç½šæ›´é‡ï¼ˆå¹³æ–¹é¡¹ï¼‰
- å¯å¾®åˆ†ï¼Œä¾¿äºä¼˜åŒ–
- å•ä½æ˜¯ç›®æ ‡å˜é‡å•ä½çš„å¹³æ–¹

#### ä»£ç ç¤ºä¾‹ï¼šè®¡ç®—MSE

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

double[] yTrue = new double[] { 100, 200, 300 };
double[] yPred = new double[] { 110, 190, 310 };

double mse = RegressionMetrics.MeanSquaredError(yTrue, yPred);
double rmse = RegressionMetrics.RootMeanSquaredError(yTrue, yPred);
double mae = RegressionMetrics.MeanAbsoluteError(yTrue, yPred);

Console.WriteLine($"MSE: {mse:F2}");   // å‡æ–¹è¯¯å·®
Console.WriteLine($"RMSE: {rmse:F2}"); // å‡æ–¹æ ¹è¯¯å·®
Console.WriteLine($"MAE: {mae:F2}");   // å¹³å‡ç»å¯¹è¯¯å·®
```

---

## è¿›é˜¶æ•™ç¨‹

### ç¬¬3è¯¾ï¼šæ­£åˆ™åŒ–æŠ€æœ¯

#### ä¸ºä»€ä¹ˆéœ€è¦æ­£åˆ™åŒ–ï¼Ÿ

**è¿‡æ‹Ÿåˆé—®é¢˜**ï¼šæ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šè¡¨ç°å¾ˆå¥½ï¼Œä½†åœ¨æµ‹è¯•é›†ä¸Šè¡¨ç°å·®ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šåœ¨æŸå¤±å‡½æ•°ä¸­æ·»åŠ æƒ©ç½šé¡¹ï¼Œé™åˆ¶æƒé‡çš„å¤§å°ã€‚

#### Ridgeå›å½’ï¼ˆL2æ­£åˆ™åŒ–ï¼‰

æŸå¤±å‡½æ•°ï¼š
```
Loss = MSE + Î± * Î£wáµ¢Â²
```

**ç‰¹ç‚¹**ï¼š
- æƒé‡è¶‹å‘äºè¾ƒå°çš„å€¼
- ä¸ä¼šå°†æƒé‡å‹ç¼©åˆ°0
- é€‚åˆç‰¹å¾é—´å­˜åœ¨å¤šé‡å…±çº¿æ€§çš„æƒ…å†µ

**ä»£ç ç¤ºä¾‹**ï¼š

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Regression;

// å‡†å¤‡æ•°æ®
double[,] X = new double[,] {
    { 1, 2 },
    { 2, 4 },
    { 3, 6 },
    { 4, 8 }
};
double[] y = new double[] { 3, 5, 7, 9 };

// Ridgeå›å½’ï¼Œalphaæ§åˆ¶æ­£åˆ™åŒ–å¼ºåº¦
var model = new RidgeRegression(alpha: 1.0);
model.Fit(X, y);

// é¢„æµ‹
double[,] XTest = new double[,] { { 5, 10 } };
double[] predictions = model.Predict(XTest);

Console.WriteLine($"é¢„æµ‹å€¼: {predictions[0]:F2}");
```

**å‚æ•°è°ƒä¼˜**ï¼š
- `alpha = 0`: ç­‰åŒäºæ™®é€šçº¿æ€§å›å½’
- `alpha` å¾ˆå°: è½»å¾®æ­£åˆ™åŒ–
- `alpha` å¾ˆå¤§: å¼ºæ­£åˆ™åŒ–ï¼Œå¯èƒ½æ¬ æ‹Ÿåˆ

#### Lassoå›å½’ï¼ˆL1æ­£åˆ™åŒ–ï¼‰

æŸå¤±å‡½æ•°ï¼š
```
Loss = MSE + Î± * Î£|wáµ¢|
```

**ç‰¹ç‚¹**ï¼š
- å¯ä»¥å°†æŸäº›æƒé‡å‹ç¼©åˆ°0
- è‡ªåŠ¨è¿›è¡Œç‰¹å¾é€‰æ‹©
- äº§ç”Ÿç¨€ç–æ¨¡å‹

**ä»£ç ç¤ºä¾‹**ï¼š

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Regression;

var model = new LassoRegression(alpha: 0.5);
model.Fit(X, y);

// æŸ¥çœ‹æœ‰å¤šå°‘ç‰¹å¾è¢«é€‰ä¸­
int nonZeroCount = model.GetNonZeroWeightsCount();
Console.WriteLine($"é€‰ä¸­çš„ç‰¹å¾æ•°: {nonZeroCount}");
```

**Ridge vs Lasso**ï¼š

| ç‰¹æ€§ | Ridge | Lasso |
|------|-------|-------|
| æ­£åˆ™åŒ–ç±»å‹ | L2 | L1 |
| ç‰¹å¾é€‰æ‹© | âŒ | âœ… |
| æƒé‡åˆ†å¸ƒ | å‡åŒ€è¾ƒå° | ç¨€ç–ï¼ˆéƒ¨åˆ†ä¸º0ï¼‰ |
| é€‚ç”¨åœºæ™¯ | æ‰€æœ‰ç‰¹å¾éƒ½é‡è¦ | éœ€è¦ç‰¹å¾é€‰æ‹© |

### ç¬¬4è¯¾ï¼šå¤šé¡¹å¼å›å½’

#### å¤„ç†éçº¿æ€§å…³ç³»

å½“æ•°æ®å‘ˆç°æ›²çº¿å…³ç³»æ—¶ï¼Œçº¿æ€§å›å½’æ•ˆæœä¸ä½³ã€‚å¤šé¡¹å¼å›å½’é€šè¿‡æ·»åŠ é«˜æ¬¡é¡¹æ¥æ‹Ÿåˆæ›²çº¿ã€‚

**åŸç†**ï¼š
```
y = wâ‚€ + wâ‚x + wâ‚‚xÂ² + wâ‚ƒxÂ³ + ...
```

**ä»£ç ç¤ºä¾‹**ï¼š

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Regression;

// éçº¿æ€§æ•°æ®ï¼šy = xÂ²
double[,] X = new double[,] {
    { 1 }, { 2 }, { 3 }, { 4 }, { 5 }
};
double[] y = new double[] { 1, 4, 9, 16, 25 };

// ä½¿ç”¨2é˜¶å¤šé¡¹å¼
var model = new PolynomialRegression(degree: 2);
model.Fit(X, y);

// é¢„æµ‹
double[,] XTest = new double[,] { { 6 } };
double[] predictions = model.Predict(XTest);

Console.WriteLine($"é¢„æµ‹å€¼: {predictions[0]:F2}"); // åº”è¯¥æ¥è¿‘36
```

**æ³¨æ„äº‹é¡¹**ï¼š
- é˜¶æ•°å¤ªä½ï¼šæ¬ æ‹Ÿåˆ
- é˜¶æ•°å¤ªé«˜ï¼šè¿‡æ‹Ÿåˆ
- é€šå¸¸ä½¿ç”¨2-4é˜¶

---

## ç²¾é€šæ•™ç¨‹

### ç¬¬5è¯¾ï¼šæ¨¡å‹è¯„ä¼°ä¸é€‰æ‹©

#### è¯„ä¼°æŒ‡æ ‡è¯¦è§£

**1. RÂ²ï¼ˆå†³å®šç³»æ•°ï¼‰**
```
RÂ² = 1 - (SS_res / SS_tot)
```
- èŒƒå›´ï¼š(-âˆ, 1]
- RÂ² = 1: å®Œç¾æ‹Ÿåˆ
- RÂ² = 0: æ¨¡å‹ç­‰åŒäºé¢„æµ‹å‡å€¼
- RÂ² < 0: æ¨¡å‹æ¯”é¢„æµ‹å‡å€¼è¿˜å·®

**2. RMSE vs MAE**
- RMSEï¼šå¯¹å¤§è¯¯å·®æ›´æ•æ„Ÿ
- MAEï¼šå¯¹å¼‚å¸¸å€¼æ›´é²æ£’

**ä»£ç ç¤ºä¾‹**ï¼š

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

double[] yTrue = new double[] { 100, 200, 300, 400 };
double[] yPred = new double[] { 110, 190, 310, 380 };

// è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
double mse = RegressionMetrics.MeanSquaredError(yTrue, yPred);
double rmse = RegressionMetrics.RootMeanSquaredError(yTrue, yPred);
double mae = RegressionMetrics.MeanAbsoluteError(yTrue, yPred);
double r2 = RegressionMetrics.RSquared(yTrue, yPred);
double mape = RegressionMetrics.MeanAbsolutePercentageError(yTrue, yPred);

Console.WriteLine($"MSE:  {mse:F2}");
Console.WriteLine($"RMSE: {rmse:F2}");
Console.WriteLine($"MAE:  {mae:F2}");
Console.WriteLine($"RÂ²:   {r2:F4}");
Console.WriteLine($"MAPE: {mape:F2}%");
```

### ç¬¬6è¯¾ï¼šäº¤å‰éªŒè¯

#### KæŠ˜äº¤å‰éªŒè¯

å°†æ•°æ®åˆ†æˆKä»½ï¼Œè½®æµä½¿ç”¨å…¶ä¸­ä¸€ä»½ä½œä¸ºæµ‹è¯•é›†ï¼Œå…¶ä½™ä½œä¸ºè®­ç»ƒé›†ã€‚

**ä»£ç ç¤ºä¾‹**ï¼š

```csharp
// ç®€å•çš„KæŠ˜äº¤å‰éªŒè¯å®ç°
public static double CrossValidate(double[,] X, double[] y, int k = 5)
{
    int n = y.Length;
    int foldSize = n / k;
    double totalR2 = 0;

    for (int i = 0; i < k; i++)
    {
        // åˆ†å‰²æ•°æ®
        var (XTrain, yTrain, XTest, yTest) = SplitData(X, y, i, foldSize);

        // è®­ç»ƒå’Œè¯„ä¼°
        var model = new LinearRegression();
        model.Fit(XTrain, yTrain);
        double[] yPred = model.Predict(XTest);

        double r2 = RegressionMetrics.RSquared(yTest, yPred);
        totalR2 += r2;
    }

    return totalR2 / k; // å¹³å‡RÂ²
}
```

---

## å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šæˆ¿ä»·é¢„æµ‹ç³»ç»Ÿ

**é—®é¢˜æè¿°**ï¼šæ ¹æ®æˆ¿å±‹ç‰¹å¾é¢„æµ‹ä»·æ ¼

**æ•°æ®ç‰¹å¾**ï¼š
- é¢ç§¯ï¼ˆå¹³æ–¹ç±³ï¼‰
- æˆ¿é—´æ•°
- æ¥¼å±‚
- å»ºé€ å¹´ä»½
- è·ç¦»å¸‚ä¸­å¿ƒè·ç¦»ï¼ˆå…¬é‡Œï¼‰

**å®Œæ•´ä»£ç **ï¼š

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Regression;
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

public class HousePricePrediction
{
    public static void Main()
    {
        // 1. å‡†å¤‡æ•°æ®
        double[,] X = new double[,] {
            // é¢ç§¯, æˆ¿é—´æ•°, æ¥¼å±‚, å¹´ä»½, è·ç¦»
            { 50,  2, 3, 2010, 5 },
            { 80,  3, 5, 2015, 3 },
            { 120, 4, 8, 2018, 2 },
            { 150, 5, 10, 2020, 1 },
            { 60,  2, 4, 2012, 4 }
        };

        double[] y = new double[] { 150, 280, 450, 600, 200 }; // ä»·æ ¼ï¼ˆä¸‡å…ƒï¼‰

        // 2. æ•°æ®åˆ†å‰²ï¼ˆ80%è®­ç»ƒï¼Œ20%æµ‹è¯•ï¼‰
        int trainSize = (int)(X.GetLength(0) * 0.8);
        var (XTrain, yTrain, XTest, yTest) = SplitData(X, y, trainSize);

        // 3. å°è¯•ä¸åŒæ¨¡å‹
        Console.WriteLine("=== çº¿æ€§å›å½’ ===");
        TestModel(new LinearRegression(), XTrain, yTrain, XTest, yTest);

        Console.WriteLine("\n=== å²­å›å½’ ===");
        TestModel(new RidgeRegression(alpha: 1.0), XTrain, yTrain, XTest, yTest);

        Console.WriteLine("\n=== Lassoå›å½’ ===");
        TestModel(new LassoRegression(alpha: 0.5), XTrain, yTrain, XTest, yTest);

        // 4. ä½¿ç”¨æœ€ä½³æ¨¡å‹è¿›è¡Œé¢„æµ‹
        var bestModel = new RidgeRegression(alpha: 1.0);
        bestModel.Fit(XTrain, yTrain);

        // é¢„æµ‹æ–°æˆ¿ä»·æ ¼
        double[,] newHouse = new double[,] { { 100, 3, 6, 2019, 2.5 } };
        double[] prediction = bestModel.Predict(newHouse);

        Console.WriteLine($"\næ–°æˆ¿é¢„æµ‹ä»·æ ¼: {prediction[0]:F2}ä¸‡å…ƒ");
    }

    static void TestModel(dynamic model, double[,] XTrain, double[] yTrain,
                         double[,] XTest, double[] yTest)
    {
        model.Fit(XTrain, yTrain);
        double[] yPred = model.Predict(XTest);

        double rmse = RegressionMetrics.RootMeanSquaredError(yTest, yPred);
        double r2 = RegressionMetrics.RSquared(yTest, yPred);

        Console.WriteLine($"RMSE: {rmse:F2}");
        Console.WriteLine($"RÂ²: {r2:F4}");
    }
}
```

### æ¡ˆä¾‹2ï¼šé”€å”®é¢„æµ‹

**é—®é¢˜**ï¼šæ ¹æ®å¹¿å‘ŠæŠ•å…¥é¢„æµ‹é”€å”®é¢

**ç‰¹å¾**ï¼š
- ç”µè§†å¹¿å‘Šè´¹ç”¨
- ç½‘ç»œå¹¿å‘Šè´¹ç”¨
- æŠ¥çº¸å¹¿å‘Šè´¹ç”¨

**å»ºè®®ä½¿ç”¨**ï¼šå¤šé¡¹å¼å›å½’ï¼ˆæ•æ‰éçº¿æ€§å…³ç³»ï¼‰

---

## ğŸ“Š ç®—æ³•é€‰æ‹©æŒ‡å—

```
å¼€å§‹
  â†“
æ•°æ®æ˜¯çº¿æ€§å…³ç³»ï¼Ÿ
  â”œâ”€ æ˜¯ â†’ ç‰¹å¾æ•°é‡å¤šï¼Ÿ
  â”‚        â”œâ”€ æ˜¯ â†’ ç‰¹å¾ç›¸å…³æ€§é«˜ï¼Ÿ
  â”‚        â”‚        â”œâ”€ æ˜¯ â†’ Ridgeå›å½’
  â”‚        â”‚        â””â”€ å¦ â†’ éœ€è¦ç‰¹å¾é€‰æ‹©ï¼Ÿ
  â”‚        â”‚                 â”œâ”€ æ˜¯ â†’ Lassoå›å½’
  â”‚        â”‚                 â””â”€ å¦ â†’ çº¿æ€§å›å½’
  â”‚        â””â”€ å¦ â†’ çº¿æ€§å›å½’
  â””â”€ å¦ â†’ å¤šé¡¹å¼å›å½’
```

## ğŸ¯ å­¦ä¹ æ£€æŸ¥æ¸…å•

### å…¥é—¨çº§
- [ ] ç†è§£å›å½’çš„åŸºæœ¬æ¦‚å¿µ
- [ ] èƒ½å¤Ÿä½¿ç”¨LinearRegressionè¿›è¡Œç®€å•é¢„æµ‹
- [ ] ç†è§£MSEå’ŒRÂ²æŒ‡æ ‡
- [ ] å®Œæˆæˆ¿ä»·é¢„æµ‹ç»ƒä¹ 

### è¿›é˜¶çº§
- [ ] ç†è§£æ­£åˆ™åŒ–çš„ä½œç”¨
- [ ] èƒ½å¤Ÿé€‰æ‹©åˆé€‚çš„alphaå‚æ•°
- [ ] æŒæ¡Ridgeå’ŒLassoçš„åŒºåˆ«
- [ ] èƒ½å¤Ÿå¤„ç†éçº¿æ€§æ•°æ®

### ç²¾é€šçº§
- [ ] èƒ½å¤Ÿå®ç°äº¤å‰éªŒè¯
- [ ] ç†è§£æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡çš„å«ä¹‰
- [ ] èƒ½å¤Ÿè¯Šæ–­è¿‡æ‹Ÿåˆ/æ¬ æ‹Ÿåˆ
- [ ] å®Œæˆå®Œæ•´çš„å®æˆ˜é¡¹ç›®

## ğŸ“š å»¶ä¼¸é˜…è¯»

- ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ç¬¬1-2ç« 
- Scikit-learnå›å½’æ–‡æ¡£
- Andrew Ngæœºå™¨å­¦ä¹ è¯¾ç¨‹Week 1-2

---

**ä¸‹ä¸€æ­¥**ï¼šå­¦ä¹ [åˆ†ç±»ç®—æ³•](../Classification/README.md)
