# åˆ†ç±»ç®—æ³•è¯¦è§£ï¼ˆClassificationï¼‰

## ğŸ“š ç›®å½•

- [ä»€ä¹ˆæ˜¯åˆ†ç±»](#ä»€ä¹ˆæ˜¯åˆ†ç±»)
- [ç®—æ³•åˆ—è¡¨](#ç®—æ³•åˆ—è¡¨)
- [å…¥é—¨æ•™ç¨‹](#å…¥é—¨æ•™ç¨‹)
- [è¿›é˜¶æ•™ç¨‹](#è¿›é˜¶æ•™ç¨‹)
- [ç²¾é€šæ•™ç¨‹](#ç²¾é€šæ•™ç¨‹)
- [å®æˆ˜æ¡ˆä¾‹](#å®æˆ˜æ¡ˆä¾‹)

## ä»€ä¹ˆæ˜¯åˆ†ç±»

åˆ†ç±»æ˜¯é¢„æµ‹**ç¦»æ•£ç±»åˆ«**çš„ç›‘ç£å­¦ä¹ ä»»åŠ¡ã€‚ç»™å®šè¾“å…¥ç‰¹å¾ï¼Œé¢„æµ‹æ ·æœ¬å±äºå“ªä¸ªç±»åˆ«ã€‚

### å…¸å‹åº”ç”¨åœºæ™¯
- ğŸ“§ åƒåœ¾é‚®ä»¶è¯†åˆ«ï¼šé‚®ä»¶æ˜¯"åƒåœ¾"è¿˜æ˜¯"æ­£å¸¸"
- ğŸ¥ ç–¾ç—…è¯Šæ–­ï¼šæ‚£è€…æ˜¯å¦æ‚£æœ‰æŸç§ç–¾ç—…
- ğŸ’³ ä¿¡ç”¨è¯„åˆ†ï¼šå®¢æˆ·æ˜¯"é«˜é£é™©"è¿˜æ˜¯"ä½é£é™©"
- ğŸ–¼ï¸ å›¾åƒè¯†åˆ«ï¼šå›¾ç‰‡ä¸­æ˜¯"çŒ«"è¿˜æ˜¯"ç‹—"
- ğŸ˜Š æƒ…æ„Ÿåˆ†æï¼šè¯„è®ºæ˜¯"æ­£é¢"è¿˜æ˜¯"è´Ÿé¢"

### åˆ†ç±»ç±»å‹

| ç±»å‹ | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| **äºŒåˆ†ç±»** | åªæœ‰ä¸¤ä¸ªç±»åˆ« | åƒåœ¾é‚®ä»¶è¯†åˆ«ï¼ˆæ˜¯/å¦ï¼‰ |
| **å¤šåˆ†ç±»** | ä¸‰ä¸ªæˆ–æ›´å¤šç±»åˆ« | é¸¢å°¾èŠ±åˆ†ç±»ï¼ˆ3ç§ï¼‰ |
| **å¤šæ ‡ç­¾** | ä¸€ä¸ªæ ·æœ¬å¯å±äºå¤šä¸ªç±»åˆ« | æ–°é—»æ ‡ç­¾ï¼ˆæ”¿æ²»+ç»æµï¼‰ |

## ç®—æ³•åˆ—è¡¨

æœ¬æ¨¡å—åŒ…å«4ä¸ªæ ¸å¿ƒåˆ†ç±»ç®—æ³•ï¼š

| ç®—æ³• | éš¾åº¦ | é€‚ç”¨åœºæ™¯ | å…³é”®ç‰¹ç‚¹ |
|------|------|----------|----------|
| **LogisticRegression** | â­â­ | äºŒåˆ†ç±»é—®é¢˜ | æ¦‚ç‡è¾“å‡ºï¼Œæ˜“è§£é‡Š |
| **KNearestNeighbors** | â­ | å°æ•°æ®é›† | ç®€å•ç›´è§‚ï¼Œæ— éœ€è®­ç»ƒ |
| **DecisionTreeClassifier** | â­â­â­ | éœ€è¦å¯è§£é‡Šæ€§ | æ ‘å½¢ç»“æ„ï¼Œæ˜“ç†è§£ |
| **NaiveBayesClassifier** | â­â­ | æ–‡æœ¬åˆ†ç±» | å¿«é€Ÿï¼Œé€‚åˆé«˜ç»´æ•°æ® |

---

## å…¥é—¨æ•™ç¨‹

### ç¬¬1è¯¾ï¼šé€»è¾‘å›å½’åŸºç¡€

#### ç†è®ºåŸºç¡€

é€»è¾‘å›å½’ç”¨äºäºŒåˆ†ç±»é—®é¢˜ï¼Œé€šè¿‡Sigmoidå‡½æ•°å°†çº¿æ€§è¾“å‡ºæ˜ å°„åˆ°[0,1]åŒºé—´ï¼š

```
P(y=1|x) = 1 / (1 + e^(-z))
å…¶ä¸­ z = wâ‚€ + wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + wâ‚™xâ‚™
```

**è¾“å‡ºè§£é‡Š**ï¼š
- P > 0.5 â†’ é¢„æµ‹ä¸ºç±»åˆ«1
- P â‰¤ 0.5 â†’ é¢„æµ‹ä¸ºç±»åˆ«0

#### ä»£ç ç¤ºä¾‹ï¼šåƒåœ¾é‚®ä»¶åˆ†ç±»

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Classification;
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

// ç¤ºä¾‹ï¼šæ ¹æ®é‚®ä»¶ç‰¹å¾åˆ¤æ–­æ˜¯å¦ä¸ºåƒåœ¾é‚®ä»¶
// ç‰¹å¾ï¼š[åŒ…å«"å…è´¹"æ¬¡æ•°, åŒ…å«"ä¸­å¥–"æ¬¡æ•°]
double[,] X = new double[,] {
    { 0, 0 },  // æ­£å¸¸é‚®ä»¶
    { 0, 1 },  // æ­£å¸¸é‚®ä»¶
    { 5, 3 },  // åƒåœ¾é‚®ä»¶
    { 8, 5 },  // åƒåœ¾é‚®ä»¶
    { 1, 0 },  // æ­£å¸¸é‚®ä»¶
    { 10, 8 }  // åƒåœ¾é‚®ä»¶
};

int[] y = new int[] { 0, 0, 1, 1, 0, 1 }; // 0=æ­£å¸¸, 1=åƒåœ¾

// 1. åˆ›å»ºæ¨¡å‹
var model = new LogisticRegression(learningRate: 0.1, maxIterations: 1000);

// 2. è®­ç»ƒæ¨¡å‹
model.Fit(X, y);

// 3. é¢„æµ‹
double[,] XTest = new double[,] { { 6, 4 } }; // æ–°é‚®ä»¶
int[] predictions = model.Predict(XTest);
double[] probabilities = model.PredictProba(XTest);

Console.WriteLine($"é¢„æµ‹ç±»åˆ«: {predictions[0]}");
Console.WriteLine($"æ˜¯åƒåœ¾é‚®ä»¶çš„æ¦‚ç‡: {probabilities[0]:P2}");

// 4. è¯„ä¼°æ¨¡å‹
int[] yPred = model.Predict(X);
double accuracy = ClassificationMetrics.Accuracy(y, yPred);
Console.WriteLine($"å‡†ç¡®ç‡: {accuracy:P2}");
```

#### ç»ƒä¹ é¢˜

1. **åŸºç¡€ç»ƒä¹ **ï¼šå­¦ç”Ÿæˆç»©åˆ†ç±»
   - è¾“å…¥ï¼šå­¦ä¹ æ—¶é—´ã€ä½œä¸šå®Œæˆç‡
   - è¾“å‡ºï¼šæ˜¯å¦åŠæ ¼ï¼ˆ0/1ï¼‰

2. **è¿›é˜¶ç»ƒä¹ **ï¼šå®¢æˆ·æµå¤±é¢„æµ‹
   - è¾“å…¥ï¼šä½¿ç”¨æ—¶é•¿ã€æŠ•è¯‰æ¬¡æ•°ã€æ¶ˆè´¹é‡‘é¢
   - è¾“å‡ºï¼šæ˜¯å¦ä¼šæµå¤±

### ç¬¬2è¯¾ï¼šKè¿‘é‚»ç®—æ³•ï¼ˆKNNï¼‰

#### ç†è®ºåŸºç¡€

KNNæ˜¯æœ€ç®€å•çš„åˆ†ç±»ç®—æ³•ï¼š
1. æ‰¾åˆ°è·ç¦»æµ‹è¯•æ ·æœ¬æœ€è¿‘çš„Kä¸ªè®­ç»ƒæ ·æœ¬
2. è¿™Kä¸ªæ ·æœ¬æŠ•ç¥¨å†³å®šç±»åˆ«
3. å¤šæ•°ç±»åˆ«å³ä¸ºé¢„æµ‹ç»“æœ

**å…³é”®å‚æ•°**ï¼š
- `k`ï¼šè¿‘é‚»æ•°é‡
  - kå¤ªå°ï¼šå®¹æ˜“è¿‡æ‹Ÿåˆ
  - kå¤ªå¤§ï¼šå®¹æ˜“æ¬ æ‹Ÿåˆ
  - é€šå¸¸é€‰æ‹©å¥‡æ•°ï¼ˆé¿å…å¹³ç¥¨ï¼‰

#### ä»£ç ç¤ºä¾‹ï¼šé¸¢å°¾èŠ±åˆ†ç±»

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Classification;

// é¸¢å°¾èŠ±æ•°æ®ï¼š[èŠ±ç“£é•¿åº¦, èŠ±ç“£å®½åº¦]
double[,] X = new double[,] {
    { 1.4, 0.2 },  // ç±»åˆ«0
    { 1.3, 0.2 },  // ç±»åˆ«0
    { 1.5, 0.2 },  // ç±»åˆ«0
    { 4.7, 1.4 },  // ç±»åˆ«1
    { 4.5, 1.5 },  // ç±»åˆ«1
    { 4.9, 1.5 },  // ç±»åˆ«1
    { 6.0, 2.5 },  // ç±»åˆ«2
    { 5.9, 2.1 },  // ç±»åˆ«2
    { 6.3, 2.3 }   // ç±»åˆ«2
};

int[] y = new int[] { 0, 0, 0, 1, 1, 1, 2, 2, 2 };

// åˆ›å»ºKNNåˆ†ç±»å™¨ï¼ˆk=3ï¼‰
var model = new KNearestNeighbors(k: 3);
model.Fit(X, y);

// é¢„æµ‹æ–°æ ·æœ¬
double[,] XTest = new double[,] { { 5.0, 1.6 } };
int[] predictions = model.Predict(XTest);

Console.WriteLine($"é¢„æµ‹ç±»åˆ«: {predictions[0]}");
```

#### KNNçš„ä¼˜ç¼ºç‚¹

**ä¼˜ç‚¹**ï¼š
- âœ… ç®€å•æ˜“æ‡‚
- âœ… æ— éœ€è®­ç»ƒè¿‡ç¨‹
- âœ… é€‚åˆå¤šåˆ†ç±»é—®é¢˜

**ç¼ºç‚¹**ï¼š
- âŒ é¢„æµ‹é€Ÿåº¦æ…¢ï¼ˆéœ€è¦è®¡ç®—æ‰€æœ‰è·ç¦»ï¼‰
- âŒ å¯¹ç‰¹å¾ç¼©æ”¾æ•æ„Ÿ
- âŒ ä¸é€‚åˆé«˜ç»´æ•°æ®ï¼ˆç»´åº¦ç¾éš¾ï¼‰

---

## è¿›é˜¶æ•™ç¨‹

### ç¬¬3è¯¾ï¼šå†³ç­–æ ‘åˆ†ç±»å™¨

#### ç†è®ºåŸºç¡€

å†³ç­–æ ‘é€šè¿‡ä¸€ç³»åˆ—if-elseè§„åˆ™è¿›è¡Œåˆ†ç±»ï¼Œç±»ä¼¼äºäººç±»çš„å†³ç­–è¿‡ç¨‹ã€‚

**æ„å»ºè¿‡ç¨‹**ï¼š
1. é€‰æ‹©æœ€ä½³ç‰¹å¾è¿›è¡Œåˆ†è£‚
2. æ ¹æ®ç‰¹å¾å€¼å°†æ•°æ®åˆ†æˆå­é›†
3. é€’å½’æ„å»ºå­æ ‘
4. è¾¾åˆ°åœæ­¢æ¡ä»¶æ—¶åˆ›å»ºå¶èŠ‚ç‚¹

**åˆ†è£‚æ ‡å‡†**ï¼šä¿¡æ¯å¢ç›Šï¼ˆåŸºäºç†µï¼‰

```
ä¿¡æ¯å¢ç›Š = çˆ¶èŠ‚ç‚¹ç†µ - å­èŠ‚ç‚¹åŠ æƒå¹³å‡ç†µ
```

#### ä»£ç ç¤ºä¾‹ï¼šä¿¡ç”¨è¯„åˆ†

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Classification;

// ä¿¡ç”¨è¯„åˆ†æ•°æ®ï¼š[å¹´é¾„, æ”¶å…¥(ä¸‡), è´Ÿå€ºç‡]
double[,] X = new double[,] {
    { 25, 3, 0.8 },   // é«˜é£é™©
    { 35, 8, 0.3 },   // ä½é£é™©
    { 45, 12, 0.2 },  // ä½é£é™©
    { 22, 2, 0.9 },   // é«˜é£é™©
    { 50, 15, 0.1 },  // ä½é£é™©
    { 28, 4, 0.7 }    // é«˜é£é™©
};

int[] y = new int[] { 1, 0, 0, 1, 0, 1 }; // 0=ä½é£é™©, 1=é«˜é£é™©

// åˆ›å»ºå†³ç­–æ ‘ï¼ˆæœ€å¤§æ·±åº¦10ï¼Œæœ€å°åˆ†è£‚æ ·æœ¬æ•°2ï¼‰
var model = new DecisionTreeClassifier(maxDepth: 10, minSamplesSplit: 2);
model.Fit(X, y);

// é¢„æµ‹
double[,] XTest = new double[,] { { 30, 6, 0.5 } };
int[] predictions = model.Predict(XTest);

Console.WriteLine($"é£é™©ç­‰çº§: {(predictions[0] == 0 ? "ä½é£é™©" : "é«˜é£é™©")}");
```

#### å†³ç­–æ ‘çš„ä¼˜ç¼ºç‚¹

**ä¼˜ç‚¹**ï¼š
- âœ… æ˜“äºç†è§£å’Œè§£é‡Š
- âœ… å¯ä»¥å¤„ç†æ•°å€¼å’Œç±»åˆ«ç‰¹å¾
- âœ… ä¸éœ€è¦ç‰¹å¾ç¼©æ”¾
- âœ… å¯ä»¥æ•æ‰éçº¿æ€§å…³ç³»

**ç¼ºç‚¹**ï¼š
- âŒ å®¹æ˜“è¿‡æ‹Ÿåˆ
- âŒ å¯¹æ•°æ®å˜åŒ–æ•æ„Ÿ
- âŒ å¯èƒ½äº§ç”Ÿåå‘æŸäº›ç±»åˆ«çš„æ ‘

**é˜²æ­¢è¿‡æ‹Ÿåˆçš„æ–¹æ³•**ï¼š
- é™åˆ¶æœ€å¤§æ·±åº¦ï¼ˆ`maxDepth`ï¼‰
- è®¾ç½®æœ€å°åˆ†è£‚æ ·æœ¬æ•°ï¼ˆ`minSamplesSplit`ï¼‰
- å‰ªæï¼ˆPruningï¼‰

### ç¬¬4è¯¾ï¼šæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨

#### ç†è®ºåŸºç¡€

åŸºäºè´å¶æ–¯å®šç†å’Œç‰¹å¾ç‹¬ç«‹æ€§å‡è®¾ï¼š

```
P(ç±»åˆ«|ç‰¹å¾) âˆ P(ç±»åˆ«) Ã— P(ç‰¹å¾â‚|ç±»åˆ«) Ã— P(ç‰¹å¾â‚‚|ç±»åˆ«) Ã— ...
```

**"æœ´ç´ "å‡è®¾**ï¼šç‰¹å¾ä¹‹é—´ç›¸äº’ç‹¬ç«‹ï¼ˆå®é™…ä¸­å¾€å¾€ä¸æˆç«‹ï¼Œä½†æ•ˆæœä»ç„¶ä¸é”™ï¼‰

**é«˜æ–¯æœ´ç´ è´å¶æ–¯**ï¼šå‡è®¾ç‰¹å¾æœä»æ­£æ€åˆ†å¸ƒ

#### ä»£ç ç¤ºä¾‹ï¼šæ–‡æœ¬æƒ…æ„Ÿåˆ†æ

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Classification;

// æ–‡æœ¬ç‰¹å¾å‘é‡ï¼ˆç®€åŒ–ç¤ºä¾‹ï¼‰
// ç‰¹å¾ï¼š[æ­£é¢è¯æ•°é‡, è´Ÿé¢è¯æ•°é‡, æ„Ÿå¹å·æ•°é‡]
double[,] X = new double[,] {
    { 5, 0, 2 },   // æ­£é¢è¯„è®º
    { 6, 1, 3 },   // æ­£é¢è¯„è®º
    { 0, 5, 1 },   // è´Ÿé¢è¯„è®º
    { 1, 6, 0 },   // è´Ÿé¢è¯„è®º
    { 4, 1, 2 },   // æ­£é¢è¯„è®º
    { 0, 7, 2 }    // è´Ÿé¢è¯„è®º
};

int[] y = new int[] { 1, 1, 0, 0, 1, 0 }; // 0=è´Ÿé¢, 1=æ­£é¢

// åˆ›å»ºæœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨
var model = new NaiveBayesClassifier();
model.Fit(X, y);

// é¢„æµ‹æ–°è¯„è®º
double[,] XTest = new double[,] { { 3, 2, 1 } };
int[] predictions = model.Predict(XTest);

Console.WriteLine($"æƒ…æ„Ÿ: {(predictions[0] == 1 ? "æ­£é¢" : "è´Ÿé¢")}");
```

#### æœ´ç´ è´å¶æ–¯çš„ä¼˜ç¼ºç‚¹

**ä¼˜ç‚¹**ï¼š
- âœ… è®­ç»ƒå’Œé¢„æµ‹é€Ÿåº¦å¿«
- âœ… é€‚åˆé«˜ç»´æ•°æ®
- âœ… å¯¹ç¼ºå¤±æ•°æ®ä¸æ•æ„Ÿ
- âœ… é€‚åˆæ–‡æœ¬åˆ†ç±»

**ç¼ºç‚¹**ï¼š
- âŒ ç‰¹å¾ç‹¬ç«‹æ€§å‡è®¾å¾€å¾€ä¸æˆç«‹
- âŒ å¯¹ç‰¹å¾åˆ†å¸ƒæ•æ„Ÿ

---

## ç²¾é€šæ•™ç¨‹

### ç¬¬5è¯¾ï¼šæ¨¡å‹è¯„ä¼°æ·±å…¥

#### æ··æ·†çŸ©é˜µ

æ··æ·†çŸ©é˜µå±•ç¤ºåˆ†ç±»ç»“æœçš„è¯¦ç»†æƒ…å†µï¼š

```
                é¢„æµ‹
              æ­£  è´Ÿ
å®  æ­£       TP  FN
é™…  è´Ÿ       FP  TN
```

- **TPï¼ˆTrue Positiveï¼‰**ï¼šæ­£ç¡®é¢„æµ‹ä¸ºæ­£
- **TNï¼ˆTrue Negativeï¼‰**ï¼šæ­£ç¡®é¢„æµ‹ä¸ºè´Ÿ
- **FPï¼ˆFalse Positiveï¼‰**ï¼šé”™è¯¯é¢„æµ‹ä¸ºæ­£ï¼ˆå‡é˜³æ€§ï¼‰
- **FNï¼ˆFalse Negativeï¼‰**ï¼šé”™è¯¯é¢„æµ‹ä¸ºè´Ÿï¼ˆå‡é˜´æ€§ï¼‰

**ä»£ç ç¤ºä¾‹**ï¼š

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

int[] yTrue = new int[] { 0, 1, 1, 0, 1, 0, 1, 1 };
int[] yPred = new int[] { 0, 1, 0, 0, 1, 1, 1, 1 };

// åˆ›å»ºæ··æ·†çŸ©é˜µ
var cm = new ConfusionMatrix(yTrue, yPred);

// æ‰“å°æ··æ·†çŸ©é˜µ
Console.WriteLine(cm.ToString());

// è·å–å„é¡¹æŒ‡æ ‡
int tp = cm.GetTruePositives(1);
int fp = cm.GetFalsePositives(1);
int fn = cm.GetFalseNegatives(1);
int tn = cm.GetTrueNegatives(1);

Console.WriteLine($"TP: {tp}, FP: {fp}, FN: {fn}, TN: {tn}");
```

#### è¯„ä¼°æŒ‡æ ‡è¯¦è§£

**1. å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰**
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)
```
- é€‚ç”¨äºç±»åˆ«å¹³è¡¡çš„æ•°æ®
- ä¸é€‚ç”¨äºç±»åˆ«ä¸å¹³è¡¡çš„æ•°æ®

**2. ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰**
```
Precision = TP / (TP + FP)
```
- é¢„æµ‹ä¸ºæ­£çš„æ ·æœ¬ä¸­ï¼ŒçœŸæ­£ä¸ºæ­£çš„æ¯”ä¾‹
- å…³æ³¨"æŸ¥å‡†ç‡"

**3. å¬å›ç‡ï¼ˆRecallï¼‰**
```
Recall = TP / (TP + FN)
```
- å®é™…ä¸ºæ­£çš„æ ·æœ¬ä¸­ï¼Œè¢«æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹
- å…³æ³¨"æŸ¥å…¨ç‡"

**4. F1åˆ†æ•°**
```
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
```
- ç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡
- å¹³è¡¡ä¸¤è€…çš„æŒ‡æ ‡

**ä»£ç ç¤ºä¾‹**ï¼š

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

int[] yTrue = new int[] { 0, 1, 1, 0, 1, 0, 1, 1 };
int[] yPred = new int[] { 0, 1, 0, 0, 1, 1, 1, 1 };

double accuracy = ClassificationMetrics.Accuracy(yTrue, yPred);
double precision = ClassificationMetrics.Precision(yTrue, yPred, positiveClass: 1);
double recall = ClassificationMetrics.Recall(yTrue, yPred, positiveClass: 1);
double f1 = ClassificationMetrics.F1Score(yTrue, yPred, positiveClass: 1);

Console.WriteLine($"å‡†ç¡®ç‡: {accuracy:P2}");
Console.WriteLine($"ç²¾ç¡®ç‡: {precision:P2}");
Console.WriteLine($"å¬å›ç‡: {recall:P2}");
Console.WriteLine($"F1åˆ†æ•°: {f1:P2}");
```

#### æŒ‡æ ‡é€‰æ‹©æŒ‡å—

| åœºæ™¯ | æ¨èæŒ‡æ ‡ | åŸå›  |
|------|----------|------|
| ç±»åˆ«å¹³è¡¡ | Accuracy | ç®€å•ç›´è§‚ |
| ç±»åˆ«ä¸å¹³è¡¡ | F1-Score | å¹³è¡¡ç²¾ç¡®ç‡å’Œå¬å›ç‡ |
| åƒåœ¾é‚®ä»¶æ£€æµ‹ | Precision | é¿å…è¯¯åˆ¤æ­£å¸¸é‚®ä»¶ |
| ç–¾ç—…è¯Šæ–­ | Recall | é¿å…æ¼è¯Š |
| æ¨èç³»ç»Ÿ | Precision@K | å…³æ³¨å‰Kä¸ªæ¨è |

### ç¬¬6è¯¾ï¼šå¤„ç†ç±»åˆ«ä¸å¹³è¡¡

#### é—®é¢˜æè¿°

ç±»åˆ«ä¸å¹³è¡¡ï¼šæŸä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡è¿œå¤šäºå…¶ä»–ç±»åˆ«ã€‚

**ç¤ºä¾‹**ï¼š
- æ¬ºè¯ˆæ£€æµ‹ï¼š99%æ­£å¸¸äº¤æ˜“ï¼Œ1%æ¬ºè¯ˆ
- ç–¾ç—…è¯Šæ–­ï¼š95%å¥åº·ï¼Œ5%æ‚£ç—…

**é—®é¢˜**ï¼šæ¨¡å‹å€¾å‘äºé¢„æµ‹å¤šæ•°ç±»åˆ«

#### è§£å†³æ–¹æ¡ˆ

**1. é‡é‡‡æ ·**
- è¿‡é‡‡æ ·ï¼ˆOversamplingï¼‰ï¼šå¢åŠ å°‘æ•°ç±»æ ·æœ¬
- æ¬ é‡‡æ ·ï¼ˆUndersamplingï¼‰ï¼šå‡å°‘å¤šæ•°ç±»æ ·æœ¬

**2. è°ƒæ•´ç±»åˆ«æƒé‡**
- ç»™å°‘æ•°ç±»æ›´é«˜çš„æƒé‡

**3. ä½¿ç”¨åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡**
- ä½¿ç”¨F1-Scoreè€ŒéAccuracy

**4. é›†æˆæ–¹æ³•**
- ä½¿ç”¨é›†æˆå­¦ä¹ ç®—æ³•

---

## å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šå®¢æˆ·æµå¤±é¢„æµ‹ç³»ç»Ÿ

**é—®é¢˜æè¿°**ï¼šé¢„æµ‹å®¢æˆ·æ˜¯å¦ä¼šæµå¤±

**æ•°æ®ç‰¹å¾**ï¼š
- ä½¿ç”¨æ—¶é•¿ï¼ˆæœˆï¼‰
- æœˆæ¶ˆè´¹é‡‘é¢
- æŠ•è¯‰æ¬¡æ•°
- å®¢æœè”ç³»æ¬¡æ•°
- æ˜¯å¦ä½¿ç”¨ä¼˜æƒ åˆ¸

**å®Œæ•´ä»£ç **ï¼š

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Classification;
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

public class CustomerChurnPrediction
{
    public static void Main()
    {
        // 1. å‡†å¤‡æ•°æ®
        double[,] X = new double[,] {
            // æ—¶é•¿, æ¶ˆè´¹, æŠ•è¯‰, è”ç³», ä¼˜æƒ åˆ¸
            { 24, 500, 0, 2, 1 },   // ä¸æµå¤±
            { 3,  100, 5, 10, 0 },  // æµå¤±
            { 36, 800, 1, 3, 1 },   // ä¸æµå¤±
            { 6,  150, 8, 15, 0 },  // æµå¤±
            { 12, 300, 2, 5, 1 },   // ä¸æµå¤±
            { 2,  80,  10, 20, 0 }, // æµå¤±
            { 48, 1000, 0, 1, 1 },  // ä¸æµå¤±
            { 5,  120, 6, 12, 0 }   // æµå¤±
        };

        int[] y = new int[] { 0, 1, 0, 1, 0, 1, 0, 1 }; // 0=ä¸æµå¤±, 1=æµå¤±

        // 2. æ•°æ®åˆ†å‰²
        int trainSize = 6;
        var (XTrain, yTrain, XTest, yTest) = SplitData(X, y, trainSize);

        // 3. å°è¯•ä¸åŒæ¨¡å‹
        Console.WriteLine("=== é€»è¾‘å›å½’ ===");
        TestClassifier(new LogisticRegression(), XTrain, yTrain, XTest, yTest);

        Console.WriteLine("\n=== KNN (k=3) ===");
        TestClassifier(new KNearestNeighbors(k: 3), XTrain, yTrain, XTest, yTest);

        Console.WriteLine("\n=== å†³ç­–æ ‘ ===");
        TestClassifier(new DecisionTreeClassifier(), XTrain, yTrain, XTest, yTest);

        Console.WriteLine("\n=== æœ´ç´ è´å¶æ–¯ ===");
        TestClassifier(new NaiveBayesClassifier(), XTrain, yTrain, XTest, yTest);

        // 4. ä½¿ç”¨æœ€ä½³æ¨¡å‹
        var bestModel = new DecisionTreeClassifier();
        bestModel.Fit(XTrain, yTrain);

        // é¢„æµ‹æ–°å®¢æˆ·
        double[,] newCustomer = new double[,] { { 8, 200, 4, 8, 0 } };
        int[] prediction = bestModel.Predict(newCustomer);

        Console.WriteLine($"\næ–°å®¢æˆ·æµå¤±é¢„æµ‹: {(prediction[0] == 1 ? "ä¼šæµå¤±" : "ä¸ä¼šæµå¤±")}");
    }

    static void TestClassifier(dynamic model, double[,] XTrain, int[] yTrain,
                               double[,] XTest, int[] yTest)
    {
        model.Fit(XTrain, yTrain);
        int[] yPred = model.Predict(XTest);

        double accuracy = ClassificationMetrics.Accuracy(yTest, yPred);
        double precision = ClassificationMetrics.Precision(yTest, yPred, 1);
        double recall = ClassificationMetrics.Recall(yTest, yPred, 1);
        double f1 = ClassificationMetrics.F1Score(yTest, yPred, 1);

        Console.WriteLine($"å‡†ç¡®ç‡: {accuracy:P2}");
        Console.WriteLine($"ç²¾ç¡®ç‡: {precision:P2}");
        Console.WriteLine($"å¬å›ç‡: {recall:P2}");
        Console.WriteLine($"F1åˆ†æ•°: {f1:P2}");
    }
}
```

### æ¡ˆä¾‹2ï¼šç–¾ç—…è¯Šæ–­ç³»ç»Ÿ

**é—®é¢˜**ï¼šæ ¹æ®ç—‡çŠ¶é¢„æµ‹æ˜¯å¦æ‚£ç—…

**ç‰¹å¾**ï¼š
- ä½“æ¸©
- è¡€å‹
- å¿ƒç‡
- ç—‡çŠ¶æŒç»­å¤©æ•°

**å»ºè®®ä½¿ç”¨**ï¼šæœ´ç´ è´å¶æ–¯ï¼ˆå¿«é€Ÿï¼Œé€‚åˆåŒ»ç–—åœºæ™¯ï¼‰

**æ³¨æ„äº‹é¡¹**ï¼š
- å¬å›ç‡æ¯”ç²¾ç¡®ç‡æ›´é‡è¦ï¼ˆé¿å…æ¼è¯Šï¼‰
- éœ€è¦å¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜

---

## ğŸ“Š ç®—æ³•é€‰æ‹©æŒ‡å—

```
å¼€å§‹
  â†“
æ•°æ®é‡å¤§ï¼Ÿ
  â”œâ”€ å¦ â†’ KNNï¼ˆç®€å•æœ‰æ•ˆï¼‰
  â””â”€ æ˜¯ â†’ éœ€è¦æ¦‚ç‡è¾“å‡ºï¼Ÿ
           â”œâ”€ æ˜¯ â†’ é€»è¾‘å›å½’æˆ–æœ´ç´ è´å¶æ–¯
           â””â”€ å¦ â†’ éœ€è¦å¯è§£é‡Šæ€§ï¼Ÿ
                    â”œâ”€ æ˜¯ â†’ å†³ç­–æ ‘
                    â””â”€ å¦ â†’ æ ¹æ®æ•°æ®ç‰¹ç‚¹é€‰æ‹©
```

## ğŸ¯ å­¦ä¹ æ£€æŸ¥æ¸…å•

### å…¥é—¨çº§
- [ ] ç†è§£åˆ†ç±»çš„åŸºæœ¬æ¦‚å¿µ
- [ ] èƒ½å¤Ÿä½¿ç”¨LogisticRegressionè¿›è¡ŒäºŒåˆ†ç±»
- [ ] ç†è§£å‡†ç¡®ç‡æŒ‡æ ‡
- [ ] å®Œæˆåƒåœ¾é‚®ä»¶åˆ†ç±»ç»ƒä¹ 

### è¿›é˜¶çº§
- [ ] æŒæ¡4ç§åˆ†ç±»ç®—æ³•çš„åŸç†
- [ ] ç†è§£æ··æ·†çŸ©é˜µ
- [ ] èƒ½å¤Ÿé€‰æ‹©åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡
- [ ] å¤„ç†å¤šåˆ†ç±»é—®é¢˜

### ç²¾é€šçº§
- [ ] èƒ½å¤Ÿå¤„ç†ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜
- [ ] ç†è§£Precision-Recallæƒè¡¡
- [ ] èƒ½å¤Ÿè°ƒä¼˜æ¨¡å‹å‚æ•°
- [ ] å®Œæˆå®Œæ•´çš„å®æˆ˜é¡¹ç›®

## ğŸ“š å»¶ä¼¸é˜…è¯»

- ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ç¬¬5-6ç« 
- Scikit-learnåˆ†ç±»æ–‡æ¡£
- Andrew Ngæœºå™¨å­¦ä¹ è¯¾ç¨‹Week 3

---

**ä¸‹ä¸€æ­¥**ï¼šå­¦ä¹ [æ¨¡å‹è¯„ä¼°](../Evaluation/README.md)
