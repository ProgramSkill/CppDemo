# æ¨¡å‹è¯„ä¼°è¯¦è§£ï¼ˆEvaluationï¼‰

## ğŸ“š ç›®å½•

- [ä¸ºä»€ä¹ˆéœ€è¦æ¨¡å‹è¯„ä¼°](#ä¸ºä»€ä¹ˆéœ€è¦æ¨¡å‹è¯„ä¼°)
- [è¯„ä¼°å·¥å…·åˆ—è¡¨](#è¯„ä¼°å·¥å…·åˆ—è¡¨)
- [å…¥é—¨æ•™ç¨‹](#å…¥é—¨æ•™ç¨‹)
- [è¿›é˜¶æ•™ç¨‹](#è¿›é˜¶æ•™ç¨‹)
- [ç²¾é€šæ•™ç¨‹](#ç²¾é€šæ•™ç¨‹)
- [å®æˆ˜æ¡ˆä¾‹](#å®æˆ˜æ¡ˆä¾‹)

## ä¸ºä»€ä¹ˆéœ€è¦æ¨¡å‹è¯„ä¼°

æ¨¡å‹è¯„ä¼°æ˜¯æœºå™¨å­¦ä¹ æµç¨‹ä¸­çš„å…³é”®ç¯èŠ‚ï¼Œç”¨äºï¼š
- âœ… è¡¡é‡æ¨¡å‹æ€§èƒ½
- âœ… æ¯”è¾ƒä¸åŒæ¨¡å‹
- âœ… å‘ç°è¿‡æ‹Ÿåˆ/æ¬ æ‹Ÿåˆ
- âœ… æŒ‡å¯¼æ¨¡å‹ä¼˜åŒ–

### è¯„ä¼°çš„é»„é‡‘æ³•åˆ™

> **æ°¸è¿œä¸è¦åœ¨è®­ç»ƒé›†ä¸Šè¯„ä¼°æ¨¡å‹ï¼**

å¿…é¡»ä½¿ç”¨ç‹¬ç«‹çš„æµ‹è¯•é›†æ¥è¯„ä¼°æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

## è¯„ä¼°å·¥å…·åˆ—è¡¨

æœ¬æ¨¡å—åŒ…å«3ä¸ªæ ¸å¿ƒè¯„ä¼°å·¥å…·ï¼š

| å·¥å…· | é€‚ç”¨åœºæ™¯ | å…³é”®æŒ‡æ ‡ |
|------|----------|----------|
| **RegressionMetrics** | å›å½’é—®é¢˜ | MSE, RMSE, MAE, RÂ², MAPE |
| **ClassificationMetrics** | åˆ†ç±»é—®é¢˜ | Accuracy, Precision, Recall, F1 |
| **ConfusionMatrix** | åˆ†ç±»é—®é¢˜ | æ··æ·†çŸ©é˜µå¯è§†åŒ– |

---

## å…¥é—¨æ•™ç¨‹

### ç¬¬1è¯¾ï¼šå›å½’è¯„ä¼°åŸºç¡€

#### æ ¸å¿ƒæŒ‡æ ‡

**1. å‡æ–¹è¯¯å·®ï¼ˆMSE - Mean Squared Errorï¼‰**

```
MSE = (1/n) Î£(yáµ¢ - Å·áµ¢)Â²
```

**ç‰¹ç‚¹**ï¼š
- å¯¹å¤§è¯¯å·®æƒ©ç½šæ›´é‡
- å•ä½æ˜¯ç›®æ ‡å˜é‡å•ä½çš„å¹³æ–¹
- å€¼è¶Šå°è¶Šå¥½

**ä»£ç ç¤ºä¾‹**ï¼š

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

double[] yTrue = new double[] { 100, 200, 300, 400 };
double[] yPred = new double[] { 110, 190, 310, 380 };

double mse = RegressionMetrics.MeanSquaredError(yTrue, yPred);
Console.WriteLine($"MSE: {mse:F2}");
// è¾“å‡º: MSE: 150.00
```

**2. å‡æ–¹æ ¹è¯¯å·®ï¼ˆRMSE - Root Mean Squared Errorï¼‰**

```
RMSE = âˆšMSE
```

**ç‰¹ç‚¹**ï¼š
- ä¸ç›®æ ‡å˜é‡åŒå•ä½
- æ›´ç›´è§‚æ˜“æ‡‚
- å€¼è¶Šå°è¶Šå¥½

**ä»£ç ç¤ºä¾‹**ï¼š

```csharp
double rmse = RegressionMetrics.RootMeanSquaredError(yTrue, yPred);
Console.WriteLine($"RMSE: {rmse:F2}");
// è¾“å‡º: RMSE: 12.25ï¼ˆä¸ä»·æ ¼å•ä½ç›¸åŒï¼‰
```

**3. å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAE - Mean Absolute Errorï¼‰**

```
MAE = (1/n) Î£|yáµ¢ - Å·áµ¢|
```

**ç‰¹ç‚¹**ï¼š
- å¯¹å¼‚å¸¸å€¼ä¸æ•æ„Ÿ
- æ˜“äºç†è§£
- å€¼è¶Šå°è¶Šå¥½

**ä»£ç ç¤ºä¾‹**ï¼š

```csharp
double mae = RegressionMetrics.MeanAbsoluteError(yTrue, yPred);
Console.WriteLine($"MAE: {mae:F2}");
// è¾“å‡º: MAE: 10.00
```

#### å®Œæ•´ç¤ºä¾‹ï¼šæˆ¿ä»·é¢„æµ‹è¯„ä¼°

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Regression;
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

// 1. è®­ç»ƒæ¨¡å‹
double[,] XTrain = new double[,] {
    { 50 }, { 80 }, { 120 }, { 150 }
};
double[] yTrain = new double[] { 150, 240, 360, 450 };

var model = new LinearRegression();
model.Fit(XTrain, yTrain);

// 2. åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹
double[,] XTest = new double[,] {
    { 60 }, { 100 }, { 140 }
};
double[] yTest = new double[] { 180, 300, 420 };
double[] yPred = model.Predict(XTest);

// 3. è®¡ç®—æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡
double mse = RegressionMetrics.MeanSquaredError(yTest, yPred);
double rmse = RegressionMetrics.RootMeanSquaredError(yTest, yPred);
double mae = RegressionMetrics.MeanAbsoluteError(yTest, yPred);
double r2 = RegressionMetrics.RSquared(yTest, yPred);

// 4. è¾“å‡ºè¯„ä¼°æŠ¥å‘Š
Console.WriteLine("=== å›å½’æ¨¡å‹è¯„ä¼°æŠ¥å‘Š ===");
Console.WriteLine($"MSE:  {mse:F2}");
Console.WriteLine($"RMSE: {rmse:F2}");
Console.WriteLine($"MAE:  {mae:F2}");
Console.WriteLine($"RÂ²:   {r2:F4}");
```

### ç¬¬2è¯¾ï¼šåˆ†ç±»è¯„ä¼°åŸºç¡€

#### æ ¸å¿ƒæŒ‡æ ‡

**1. å‡†ç¡®ç‡ï¼ˆAccuracyï¼‰**

```
Accuracy = æ­£ç¡®é¢„æµ‹æ•° / æ€»æ ·æœ¬æ•°
```

**ä»£ç ç¤ºä¾‹**ï¼š

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

int[] yTrue = new int[] { 0, 1, 1, 0, 1, 0, 1, 1 };
int[] yPred = new int[] { 0, 1, 0, 0, 1, 1, 1, 1 };

double accuracy = ClassificationMetrics.Accuracy(yTrue, yPred);
Console.WriteLine($"å‡†ç¡®ç‡: {accuracy:P2}");
// è¾“å‡º: å‡†ç¡®ç‡: 75.00%
```

**é€‚ç”¨åœºæ™¯**ï¼š
- âœ… ç±»åˆ«å¹³è¡¡çš„æ•°æ®
- âŒ ç±»åˆ«ä¸å¹³è¡¡çš„æ•°æ®

**2. ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰**

```
Precision = TP / (TP + FP)
```

**å«ä¹‰**ï¼šé¢„æµ‹ä¸ºæ­£çš„æ ·æœ¬ä¸­ï¼ŒçœŸæ­£ä¸ºæ­£çš„æ¯”ä¾‹

**ä»£ç ç¤ºä¾‹**ï¼š

```csharp
double precision = ClassificationMetrics.Precision(yTrue, yPred, positiveClass: 1);
Console.WriteLine($"ç²¾ç¡®ç‡: {precision:P2}");
```

**3. å¬å›ç‡ï¼ˆRecallï¼‰**

```
Recall = TP / (TP + FN)
```

**å«ä¹‰**ï¼šå®é™…ä¸ºæ­£çš„æ ·æœ¬ä¸­ï¼Œè¢«æ­£ç¡®é¢„æµ‹çš„æ¯”ä¾‹

**ä»£ç ç¤ºä¾‹**ï¼š

```csharp
double recall = ClassificationMetrics.Recall(yTrue, yPred, positiveClass: 1);
Console.WriteLine($"å¬å›ç‡: {recall:P2}");
```

**4. F1åˆ†æ•°**

```
F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)
```

**å«ä¹‰**ï¼šç²¾ç¡®ç‡å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡

**ä»£ç ç¤ºä¾‹**ï¼š

```csharp
double f1 = ClassificationMetrics.F1Score(yTrue, yPred, positiveClass: 1);
Console.WriteLine($"F1åˆ†æ•°: {f1:P2}");
```

#### å®Œæ•´ç¤ºä¾‹ï¼šåƒåœ¾é‚®ä»¶åˆ†ç±»è¯„ä¼°

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Classification;
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

// 1. è®­ç»ƒæ¨¡å‹
double[,] XTrain = new double[,] {
    { 0, 0 }, { 0, 1 }, { 5, 3 }, { 8, 5 }
};
int[] yTrain = new int[] { 0, 0, 1, 1 };

var model = new LogisticRegression();
model.Fit(XTrain, yTrain);

// 2. åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹
double[,] XTest = new double[,] {
    { 1, 0 }, { 6, 4 }, { 0, 0 }, { 10, 8 }
};
int[] yTest = new int[] { 0, 1, 0, 1 };
int[] yPred = model.Predict(XTest);

// 3. è®¡ç®—æ‰€æœ‰è¯„ä¼°æŒ‡æ ‡
double accuracy = ClassificationMetrics.Accuracy(yTest, yPred);
double precision = ClassificationMetrics.Precision(yTest, yPred, 1);
double recall = ClassificationMetrics.Recall(yTest, yPred, 1);
double f1 = ClassificationMetrics.F1Score(yTest, yPred, 1);

// 4. è¾“å‡ºè¯„ä¼°æŠ¥å‘Š
Console.WriteLine("=== åˆ†ç±»æ¨¡å‹è¯„ä¼°æŠ¥å‘Š ===");
Console.WriteLine($"å‡†ç¡®ç‡: {accuracy:P2}");
Console.WriteLine($"ç²¾ç¡®ç‡: {precision:P2}");
Console.WriteLine($"å¬å›ç‡: {recall:P2}");
Console.WriteLine($"F1åˆ†æ•°: {f1:P2}");
```

---

## è¿›é˜¶æ•™ç¨‹

### ç¬¬3è¯¾ï¼šRÂ²å†³å®šç³»æ•°æ·±å…¥ç†è§£

#### ç†è®ºåŸºç¡€

RÂ²ï¼ˆR-squaredï¼‰è¡¡é‡æ¨¡å‹è§£é‡Šçš„æ–¹å·®æ¯”ä¾‹ï¼š

```
RÂ² = 1 - (SS_res / SS_tot)

å…¶ä¸­ï¼š
SS_res = Î£(yáµ¢ - Å·áµ¢)Â²  ï¼ˆæ®‹å·®å¹³æ–¹å’Œï¼‰
SS_tot = Î£(yáµ¢ - È³)Â²   ï¼ˆæ€»å¹³æ–¹å’Œï¼‰
```

#### RÂ²çš„å«ä¹‰

| RÂ²å€¼ | å«ä¹‰ | æ¨¡å‹è´¨é‡ |
|------|------|----------|
| 1.0 | å®Œç¾æ‹Ÿåˆ | ç†æƒ³çŠ¶æ€ |
| 0.9-1.0 | éå¸¸å¥½ | ä¼˜ç§€ |
| 0.7-0.9 | è¾ƒå¥½ | è‰¯å¥½ |
| 0.5-0.7 | ä¸€èˆ¬ | å¯æ¥å— |
| < 0.5 | è¾ƒå·® | éœ€è¦æ”¹è¿› |
| < 0 | å¾ˆå·® | æ¯”é¢„æµ‹å‡å€¼è¿˜å·® |

**ä»£ç ç¤ºä¾‹**ï¼š

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

double[] yTrue = new double[] { 100, 200, 300, 400, 500 };
double[] yPred = new double[] { 110, 190, 310, 390, 510 };

double r2 = RegressionMetrics.RSquared(yTrue, yPred);
Console.WriteLine($"RÂ²: {r2:F4}");
Console.WriteLine($"æ¨¡å‹è§£é‡Šäº† {r2:P2} çš„æ–¹å·®");
```

### ç¬¬4è¯¾ï¼šæ··æ·†çŸ©é˜µè¯¦è§£

#### ç†è®ºåŸºç¡€

æ··æ·†çŸ©é˜µæ˜¯åˆ†ç±»é—®é¢˜è¯„ä¼°çš„æ ¸å¿ƒå·¥å…·ï¼š

```
                é¢„æµ‹
              æ­£ç±»  è´Ÿç±»
å®  æ­£ç±»      TP    FN
é™…  è´Ÿç±»      FP    TN
```

**æœ¯è¯­è§£é‡Š**ï¼š
- **TPï¼ˆTrue Positiveï¼‰**ï¼šçœŸæ­£ä¾‹ - æ­£ç¡®é¢„æµ‹ä¸ºæ­£
- **TNï¼ˆTrue Negativeï¼‰**ï¼šçœŸè´Ÿä¾‹ - æ­£ç¡®é¢„æµ‹ä¸ºè´Ÿ
- **FPï¼ˆFalse Positiveï¼‰**ï¼šå‡æ­£ä¾‹ - é”™è¯¯é¢„æµ‹ä¸ºæ­£ï¼ˆç¬¬ä¸€ç±»é”™è¯¯ï¼‰
- **FNï¼ˆFalse Negativeï¼‰**ï¼šå‡è´Ÿä¾‹ - é”™è¯¯é¢„æµ‹ä¸ºè´Ÿï¼ˆç¬¬äºŒç±»é”™è¯¯ï¼‰

#### ä»£ç ç¤ºä¾‹ï¼šåˆ›å»ºå’Œåˆ†ææ··æ·†çŸ©é˜µ

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

int[] yTrue = new int[] { 0, 1, 1, 0, 1, 0, 1, 1, 0, 0 };
int[] yPred = new int[] { 0, 1, 0, 0, 1, 1, 1, 1, 0, 1 };

// åˆ›å»ºæ··æ·†çŸ©é˜µ
var cm = new ConfusionMatrix(yTrue, yPred);

// æ‰“å°æ··æ·†çŸ©é˜µ
Console.WriteLine(cm.ToString());

// è·å–å„é¡¹ç»Ÿè®¡
int tp = cm.GetTruePositives(1);
int tn = cm.GetTrueNegatives(1);
int fp = cm.GetFalsePositives(1);
int fn = cm.GetFalseNegatives(1);

Console.WriteLine($"\nç»Ÿè®¡ä¿¡æ¯:");
Console.WriteLine($"çœŸæ­£ä¾‹(TP): {tp}");
Console.WriteLine($"çœŸè´Ÿä¾‹(TN): {tn}");
Console.WriteLine($"å‡æ­£ä¾‹(FP): {fp}");
Console.WriteLine($"å‡è´Ÿä¾‹(FN): {fn}");

// æ‰‹åŠ¨è®¡ç®—æŒ‡æ ‡
double precision = (double)tp / (tp + fp);
double recall = (double)tp / (tp + fn);
double accuracy = (double)(tp + tn) / (tp + tn + fp + fn);

Console.WriteLine($"\nåŸºäºæ··æ·†çŸ©é˜µçš„æŒ‡æ ‡:");
Console.WriteLine($"ç²¾ç¡®ç‡: {precision:P2}");
Console.WriteLine($"å¬å›ç‡: {recall:P2}");
Console.WriteLine($"å‡†ç¡®ç‡: {accuracy:P2}");
```

### ç¬¬5è¯¾ï¼šPrecision-Recallæƒè¡¡

#### ç†è®ºåŸºç¡€

ç²¾ç¡®ç‡å’Œå¬å›ç‡é€šå¸¸å­˜åœ¨æƒè¡¡å…³ç³»ï¼š
- æé«˜é˜ˆå€¼ â†’ ç²¾ç¡®ç‡â†‘ï¼Œå¬å›ç‡â†“
- é™ä½é˜ˆå€¼ â†’ ç²¾ç¡®ç‡â†“ï¼Œå¬å›ç‡â†‘

#### ä¸åŒåœºæ™¯çš„é€‰æ‹©

**1. é‡è§†ç²¾ç¡®ç‡çš„åœºæ™¯**
- åƒåœ¾é‚®ä»¶è¿‡æ»¤ï¼šé¿å…è¯¯åˆ¤æ­£å¸¸é‚®ä»¶
- æ¨èç³»ç»Ÿï¼šç¡®ä¿æ¨èçš„éƒ½æ˜¯ç”¨æˆ·å–œæ¬¢çš„
- å¹¿å‘ŠæŠ•æ”¾ï¼šé¿å…æµªè´¹å¹¿å‘Šè´¹

**2. é‡è§†å¬å›ç‡çš„åœºæ™¯**
- ç–¾ç—…è¯Šæ–­ï¼šé¿å…æ¼è¯Š
- æ¬ºè¯ˆæ£€æµ‹ï¼šä¸èƒ½æ”¾è¿‡ä»»ä½•æ¬ºè¯ˆ
- å®‰å…¨æ£€æµ‹ï¼šå®å¯è¯¯æŠ¥ï¼Œä¸å¯æ¼æŠ¥

**3. å¹³è¡¡ä¸¤è€…çš„åœºæ™¯**
- å®¢æˆ·æµå¤±é¢„æµ‹
- ä¿¡ç”¨è¯„åˆ†
- ä¸€èˆ¬åˆ†ç±»ä»»åŠ¡

**ä»£ç ç¤ºä¾‹ï¼šè°ƒæ•´é˜ˆå€¼**

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Classification;

var model = new LogisticRegression();
model.Fit(XTrain, yTrain);

// è·å–æ¦‚ç‡é¢„æµ‹
double[] probabilities = model.PredictProba(XTest);

// å°è¯•ä¸åŒé˜ˆå€¼
double[] thresholds = new double[] { 0.3, 0.5, 0.7 };

foreach (var threshold in thresholds)
{
    // æ ¹æ®é˜ˆå€¼è½¬æ¢ä¸ºç±»åˆ«
    int[] predictions = probabilities.Select(p => p >= threshold ? 1 : 0).ToArray();

    double precision = ClassificationMetrics.Precision(yTest, predictions, 1);
    double recall = ClassificationMetrics.Recall(yTest, predictions, 1);

    Console.WriteLine($"é˜ˆå€¼ {threshold:F1}:");
    Console.WriteLine($"  ç²¾ç¡®ç‡: {precision:P2}");
    Console.WriteLine($"  å¬å›ç‡: {recall:P2}");
}
```

---

## ç²¾é€šæ•™ç¨‹

### ç¬¬6è¯¾ï¼šäº¤å‰éªŒè¯

#### ç†è®ºåŸºç¡€

äº¤å‰éªŒè¯æ˜¯è¯„ä¼°æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„é‡è¦æŠ€æœ¯ï¼Œé¿å…å•æ¬¡åˆ†å‰²çš„å¶ç„¶æ€§ã€‚

**KæŠ˜äº¤å‰éªŒè¯æµç¨‹**ï¼š
1. å°†æ•°æ®åˆ†æˆKä»½
2. è½®æµä½¿ç”¨å…¶ä¸­ä¸€ä»½ä½œä¸ºæµ‹è¯•é›†
3. å…¶ä½™K-1ä»½ä½œä¸ºè®­ç»ƒé›†
4. è®¡ç®—Kæ¬¡è¯„ä¼°æŒ‡æ ‡çš„å¹³å‡å€¼

#### ä»£ç ç¤ºä¾‹ï¼šå®ç°KæŠ˜äº¤å‰éªŒè¯

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Regression;
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

public class CrossValidation
{
    public static double KFoldCV(double[,] X, double[] y, int k = 5)
    {
        int n = y.Length;
        int foldSize = n / k;
        double totalR2 = 0;

        for (int fold = 0; fold < k; fold++)
        {
            // åˆ†å‰²æ•°æ®
            int testStart = fold * foldSize;
            int testEnd = (fold == k - 1) ? n : testStart + foldSize;

            var (XTrain, yTrain, XTest, yTest) = SplitFold(X, y, testStart, testEnd);

            // è®­ç»ƒå’Œè¯„ä¼°
            var model = new LinearRegression();
            model.Fit(XTrain, yTrain);
            double[] yPred = model.Predict(XTest);

            double r2 = RegressionMetrics.RSquared(yTest, yPred);
            totalR2 += r2;

            Console.WriteLine($"Fold {fold + 1}: RÂ² = {r2:F4}");
        }

        double avgR2 = totalR2 / k;
        Console.WriteLine($"\nå¹³å‡ RÂ²: {avgR2:F4}");

        return avgR2;
    }

    private static (double[,], double[], double[,], double[]) SplitFold(
        double[,] X, double[] y, int testStart, int testEnd)
    {
        int n = y.Length;
        int m = X.GetLength(1);
        int testSize = testEnd - testStart;
        int trainSize = n - testSize;

        double[,] XTrain = new double[trainSize, m];
        double[] yTrain = new double[trainSize];
        double[,] XTest = new double[testSize, m];
        double[] yTest = new double[testSize];

        int trainIdx = 0;
        for (int i = 0; i < n; i++)
        {
            if (i >= testStart && i < testEnd)
            {
                // æµ‹è¯•é›†
                int testIdx = i - testStart;
                for (int j = 0; j < m; j++)
                    XTest[testIdx, j] = X[i, j];
                yTest[testIdx] = y[i];
            }
            else
            {
                // è®­ç»ƒé›†
                for (int j = 0; j < m; j++)
                    XTrain[trainIdx, j] = X[i, j];
                yTrain[trainIdx] = y[i];
                trainIdx++;
            }
        }

        return (XTrain, yTrain, XTest, yTest);
    }
}
```

### ç¬¬7è¯¾ï¼šå­¦ä¹ æ›²çº¿åˆ†æ

#### ç†è®ºåŸºç¡€

å­¦ä¹ æ›²çº¿å±•ç¤ºè®­ç»ƒé›†å¤§å°ä¸æ¨¡å‹æ€§èƒ½çš„å…³ç³»ï¼Œç”¨äºè¯Šæ–­ï¼š
- **è¿‡æ‹Ÿåˆ**ï¼šè®­ç»ƒè¯¯å·®ä½ï¼ŒéªŒè¯è¯¯å·®é«˜
- **æ¬ æ‹Ÿåˆ**ï¼šè®­ç»ƒè¯¯å·®å’ŒéªŒè¯è¯¯å·®éƒ½é«˜
- **è‰¯å¥½æ‹Ÿåˆ**ï¼šè®­ç»ƒè¯¯å·®å’ŒéªŒè¯è¯¯å·®éƒ½ä½ä¸”æ¥è¿‘

#### ä»£ç ç¤ºä¾‹ï¼šç»˜åˆ¶å­¦ä¹ æ›²çº¿æ•°æ®

```csharp
public class LearningCurve
{
    public static void PlotLearningCurve(double[,] X, double[] y)
    {
        int n = y.Length;
        int[] trainSizes = new int[] {
            n / 10, n / 5, n / 3, n / 2, (int)(n * 0.7), (int)(n * 0.9)
        };

        Console.WriteLine("è®­ç»ƒé›†å¤§å°\tè®­ç»ƒRÂ²\téªŒè¯RÂ²");
        Console.WriteLine("----------------------------------------");

        foreach (var size in trainSizes)
        {
            // ä½¿ç”¨å‰sizeä¸ªæ ·æœ¬è®­ç»ƒ
            var (XTrain, yTrain, XVal, yVal) = SplitData(X, y, size);

            var model = new LinearRegression();
            model.Fit(XTrain, yTrain);

            // è®¡ç®—è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„RÂ²
            double[] yTrainPred = model.Predict(XTrain);
            double[] yValPred = model.Predict(XVal);

            double trainR2 = RegressionMetrics.RSquared(yTrain, yTrainPred);
            double valR2 = RegressionMetrics.RSquared(yVal, yValPred);

            Console.WriteLine($"{size}\t\t{trainR2:F4}\t{valR2:F4}");
        }
    }
}
```

---

## å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šå®Œæ•´çš„æ¨¡å‹è¯„ä¼°æµç¨‹

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Regression;
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

public class CompleteEvaluationPipeline
{
    public static void Main()
    {
        // 1. å‡†å¤‡æ•°æ®
        double[,] X = LoadData();
        double[] y = LoadLabels();

        // 2. æ•°æ®åˆ†å‰²ï¼ˆ70%è®­ç»ƒï¼Œ15%éªŒè¯ï¼Œ15%æµ‹è¯•ï¼‰
        var (XTrain, yTrain, XVal, yVal, XTest, yTest) =
            SplitTrainValTest(X, y, 0.7, 0.15, 0.15);

        // 3. è®­ç»ƒæ¨¡å‹
        var model = new LinearRegression();
        model.Fit(XTrain, yTrain);

        // 4. åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°ï¼ˆç”¨äºè°ƒå‚ï¼‰
        Console.WriteLine("=== éªŒè¯é›†è¯„ä¼° ===");
        EvaluateRegression(model, XVal, yVal);

        // 5. åœ¨æµ‹è¯•é›†ä¸Šæœ€ç»ˆè¯„ä¼°
        Console.WriteLine("\n=== æµ‹è¯•é›†è¯„ä¼°ï¼ˆæœ€ç»ˆæ€§èƒ½ï¼‰ ===");
        EvaluateRegression(model, XTest, yTest);

        // 6. äº¤å‰éªŒè¯è¯„ä¼°
        Console.WriteLine("\n=== 5æŠ˜äº¤å‰éªŒè¯ ===");
        double cvScore = CrossValidation.KFoldCV(XTrain, yTrain, k: 5);

        // 7. å­¦ä¹ æ›²çº¿åˆ†æ
        Console.WriteLine("\n=== å­¦ä¹ æ›²çº¿ ===");
        LearningCurve.PlotLearningCurve(XTrain, yTrain);
    }

    static void EvaluateRegression(LinearRegression model, double[,] X, double[] y)
    {
        double[] yPred = model.Predict(X);

        double mse = RegressionMetrics.MeanSquaredError(y, yPred);
        double rmse = RegressionMetrics.RootMeanSquaredError(y, yPred);
        double mae = RegressionMetrics.MeanAbsoluteError(y, yPred);
        double r2 = RegressionMetrics.RSquared(y, yPred);
        double mape = RegressionMetrics.MeanAbsolutePercentageError(y, yPred);

        Console.WriteLine($"MSE:  {mse:F2}");
        Console.WriteLine($"RMSE: {rmse:F2}");
        Console.WriteLine($"MAE:  {mae:F2}");
        Console.WriteLine($"RÂ²:   {r2:F4}");
        Console.WriteLine($"MAPE: {mape:F2}%");
    }
}
```

### æ¡ˆä¾‹2ï¼šåˆ†ç±»æ¨¡å‹å®Œæ•´è¯„ä¼°

```csharp
using ArtificialIntelligence.MachineLearning.Supervised.Classification;
using ArtificialIntelligence.MachineLearning.Supervised.Evaluation;

public class ClassificationEvaluation
{
    public static void Main()
    {
        // 1. å‡†å¤‡æ•°æ®
        double[,] X = LoadData();
        int[] y = LoadLabels();

        // 2. æ•°æ®åˆ†å‰²
        var (XTrain, yTrain, XTest, yTest) = SplitData(X, y, 0.8);

        // 3. è®­ç»ƒæ¨¡å‹
        var model = new LogisticRegression();
        model.Fit(XTrain, yTrain);

        // 4. é¢„æµ‹
        int[] yPred = model.Predict(XTest);

        // 5. è®¡ç®—æ‰€æœ‰æŒ‡æ ‡
        Console.WriteLine("=== åˆ†ç±»è¯„ä¼°æŠ¥å‘Š ===\n");

        double accuracy = ClassificationMetrics.Accuracy(yTest, yPred);
        double precision = ClassificationMetrics.Precision(yTest, yPred, 1);
        double recall = ClassificationMetrics.Recall(yTest, yPred, 1);
        double f1 = ClassificationMetrics.F1Score(yTest, yPred, 1);
        double specificity = ClassificationMetrics.Specificity(yTest, yPred, 1);

        Console.WriteLine($"å‡†ç¡®ç‡:   {accuracy:P2}");
        Console.WriteLine($"ç²¾ç¡®ç‡:   {precision:P2}");
        Console.WriteLine($"å¬å›ç‡:   {recall:P2}");
        Console.WriteLine($"F1åˆ†æ•°:   {f1:P2}");
        Console.WriteLine($"ç‰¹å¼‚åº¦:   {specificity:P2}");

        // 6. æ··æ·†çŸ©é˜µ
        Console.WriteLine("\n=== æ··æ·†çŸ©é˜µ ===");
        var cm = new ConfusionMatrix(yTest, yPred);
        Console.WriteLine(cm.ToString());

        // 7. è¯¦ç»†åˆ†æ
        Console.WriteLine("\n=== è¯¦ç»†åˆ†æ ===");
        int tp = cm.GetTruePositives(1);
        int tn = cm.GetTrueNegatives(1);
        int fp = cm.GetFalsePositives(1);
        int fn = cm.GetFalseNegatives(1);

        Console.WriteLine($"çœŸæ­£ä¾‹: {tp}");
        Console.WriteLine($"çœŸè´Ÿä¾‹: {tn}");
        Console.WriteLine($"å‡æ­£ä¾‹: {fp} (è¯¯æŠ¥)");
        Console.WriteLine($"å‡è´Ÿä¾‹: {fn} (æ¼æŠ¥)");
    }
}
```

---

## ğŸ“Š è¯„ä¼°æŒ‡æ ‡é€‰æ‹©æŒ‡å—

### å›å½’é—®é¢˜

```
å¼€å§‹
  â†“
å…³å¿ƒé¢„æµ‹è¯¯å·®çš„å•ä½ï¼Ÿ
  â”œâ”€ æ˜¯ â†’ RMSEæˆ–MAE
  â”‚        â”œâ”€ å¯¹å¼‚å¸¸å€¼æ•æ„Ÿï¼Ÿ
  â”‚        â”‚   â”œâ”€ æ˜¯ â†’ RMSE
  â”‚        â”‚   â””â”€ å¦ â†’ MAE
  â””â”€ å¦ â†’ å…³å¿ƒè§£é‡Šæ–¹å·®ï¼Ÿ
           â”œâ”€ æ˜¯ â†’ RÂ²
           â””â”€ å¦ â†’ å…³å¿ƒç™¾åˆ†æ¯”è¯¯å·®ï¼Ÿ
                    â””â”€ æ˜¯ â†’ MAPE
```

### åˆ†ç±»é—®é¢˜

```
å¼€å§‹
  â†“
ç±»åˆ«å¹³è¡¡ï¼Ÿ
  â”œâ”€ æ˜¯ â†’ Accuracy
  â””â”€ å¦ â†’ å…³æ³¨ä»€ä¹ˆï¼Ÿ
           â”œâ”€ é¿å…è¯¯æŠ¥ â†’ Precision
           â”œâ”€ é¿å…æ¼æŠ¥ â†’ Recall
           â””â”€ å¹³è¡¡ä¸¤è€… â†’ F1-Score
```

## ğŸ¯ å­¦ä¹ æ£€æŸ¥æ¸…å•

### å…¥é—¨çº§
- [ ] ç†è§£MSEã€RMSEã€MAEçš„å«ä¹‰
- [ ] ç†è§£Accuracyã€Precisionã€Recall
- [ ] èƒ½å¤Ÿè®¡ç®—åŸºæœ¬è¯„ä¼°æŒ‡æ ‡
- [ ] ç†è§£è®­ç»ƒé›†/æµ‹è¯•é›†åˆ†å‰²çš„é‡è¦æ€§

### è¿›é˜¶çº§
- [ ] ç†è§£RÂ²çš„å«ä¹‰å’Œåº”ç”¨
- [ ] èƒ½å¤Ÿåˆ›å»ºå’Œåˆ†ææ··æ·†çŸ©é˜µ
- [ ] ç†è§£Precision-Recallæƒè¡¡
- [ ] èƒ½å¤Ÿé€‰æ‹©åˆé€‚çš„è¯„ä¼°æŒ‡æ ‡

### ç²¾é€šçº§
- [ ] èƒ½å¤Ÿå®ç°äº¤å‰éªŒè¯
- [ ] èƒ½å¤Ÿç»˜åˆ¶å’Œåˆ†æå­¦ä¹ æ›²çº¿
- [ ] èƒ½å¤Ÿè¯Šæ–­è¿‡æ‹Ÿåˆ/æ¬ æ‹Ÿåˆ
- [ ] èƒ½å¤Ÿè¿›è¡Œå®Œæ•´çš„æ¨¡å‹è¯„ä¼°æµç¨‹

## ğŸ“š å»¶ä¼¸é˜…è¯»

- ã€Šç»Ÿè®¡å­¦ä¹ æ–¹æ³•ã€‹ç¬¬8ç« 
- Scikit-learnæ¨¡å‹è¯„ä¼°æ–‡æ¡£
- "Precision and Recall" - Wikipedia

---

**æ­å–œï¼** ä½ å·²ç»å®Œæˆäº†ç›‘ç£å­¦ä¹ çš„å…¨éƒ¨æ•™ç¨‹ã€‚ç»§ç»­æ¢ç´¢å…¶ä»–æ¨¡å—å§ï¼ğŸ‰
